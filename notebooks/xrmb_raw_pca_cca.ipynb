{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4715ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa443ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from complexity_regularized_dcca.data.xrmb import XRMBData\n",
    "from complexity_regularized_dcca.algorithms.correlation import CCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC as SVM\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from complexity_regularized_dcca.algorithms.losses_metrics import MetricDict, MovingMetric\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3153e6",
   "metadata": {},
   "source": [
    "# Dataprovider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a52d6c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 10:57:44.886184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 10:57:44.892036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 10:57:44.892172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 10:57:44.892690: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-05 10:57:44.893775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 10:57:44.893895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 10:57:44.893986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 10:57:45.399954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 10:57:45.400101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 10:57:45.400201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 10:57:45.400292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22291 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "dataprovider = XRMBData(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca08a6a",
   "metadata": {},
   "source": [
    "# Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae397e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits_for_acc = dataprovider.test_data\n",
    "\n",
    "accs = []\n",
    "for split in data_splits_for_acc:\n",
    "    outputs_met_train, labels_met_train = MetricDict(), MetricDict()\n",
    "    for data in split['train']:\n",
    "        outputs_met_train.update(dict(view_0=data['nn_input_0']))\n",
    "        labels_met_train.update(dict(labels=data['labels'].numpy()))\n",
    "\n",
    "    netw_output_train = outputs_met_train.output()\n",
    "    labels_train = labels_met_train.output()['labels']\n",
    "    X_train = netw_output_train['view_0']\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "    X_train = scaler.transform(X_train)    \n",
    "\n",
    "    svm_model = SVM(random_state=333)\n",
    "    svm_model.fit(X_train, labels_train)\n",
    "\n",
    "    outputs_met_val, labels_met_val = MetricDict(), MetricDict()\n",
    "    for data in split['val']:\n",
    "        outputs_met_val.update(dict(view_0=data['nn_input_0']))\n",
    "        labels_met_val.update(dict(labels=data['labels'].numpy()))\n",
    "\n",
    "    netw_output_val = outputs_met_val.output()\n",
    "    labels_val = labels_met_val.output()['labels']\n",
    "\n",
    "    X_val = netw_output_val['view_0']\n",
    "\n",
    "    X_val = scaler.transform(X_val)\n",
    "\n",
    "    predictions = svm_model.predict(X_val)\n",
    "    svm_acc = accuracy_score(labels_val, predictions)\n",
    "    accs.append(svm_acc)\n",
    "    \n",
    "print(accs)\n",
    "print(np.mean(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de7a88",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d336dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b873e5cd8184002944b742ffb100628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "[0.4377038135022234, 0.41549656380541705, 0.43364596808969386]\n",
      "0.4289487817991114\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "pca_train_met = MetricDict()\n",
    "for batch in dataprovider.training_data:\n",
    "    pca_train_met.update(batch)\n",
    "    \n",
    "pca_train = pca_train_met.output()\n",
    "\n",
    "data_splits_for_acc = dataprovider.test_data\n",
    "\n",
    "results_dict = dict()\n",
    "\n",
    "for pca_dim in tqdm([120, 110, 100, 90, 80, 70, 60, 50, 40, 30, 20, 10]):\n",
    "\n",
    "    pca = PCA(n_components=pca_dim, random_state=333).fit(pca_train['nn_input_0'])\n",
    "\n",
    "    accs = []\n",
    "    for split in data_splits_for_acc:\n",
    "        outputs_met_train, labels_met_train = MetricDict(), MetricDict()\n",
    "        for data in split['train']:\n",
    "            pca_transformed = pca.transform(data['nn_input_0'])\n",
    "            outputs_met_train.update(dict(latent_view_0=pca_transformed))\n",
    "            labels_met_train.update(dict(labels=data['labels'].numpy()))\n",
    "\n",
    "        netw_output_train = outputs_met_train.output()\n",
    "        labels_train = labels_met_train.output()['labels']\n",
    "        X_train = netw_output_train['latent_view_0']\n",
    "\n",
    "        scaler = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "        X_train = scaler.transform(X_train)    \n",
    "\n",
    "        svm_model = SVM(random_state=333)\n",
    "        svm_model.fit(X_train, labels_train)\n",
    "\n",
    "        outputs_met_val, labels_met_val = MetricDict(), MetricDict()\n",
    "        for data in split['val']:\n",
    "            pca_transformed = pca.transform(data['nn_input_0'])\n",
    "            outputs_met_val.update(dict(latent_view_0=pca_transformed))\n",
    "            labels_met_val.update(dict(labels=data['labels'].numpy()))\n",
    "\n",
    "        netw_output_val = outputs_met_val.output()\n",
    "        labels_val = labels_met_val.output()['labels']\n",
    "\n",
    "        X_val = netw_output_val['latent_view_0']\n",
    "\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        predictions = svm_model.predict(X_val)\n",
    "        svm_acc = accuracy_score(labels_val, predictions)\n",
    "        accs.append(svm_acc)\n",
    "        \n",
    "    results_dict[pca_dim] = dict(accuracies=accs, mean=np.mean(accs))\n",
    "        \n",
    "    print(pca_dim)\n",
    "    print(accs)\n",
    "    print(np.mean(accs))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f149b5fe",
   "metadata": {},
   "source": [
    "# CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b49bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ccd1723227b4d9e92f9dd96a287943f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a87c2a390fd4c6cb48ebe9d6d76de6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 10:57:52.076066: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-09-05 10:57:52.101850: I tensorflow/core/util/cuda_solvers.cc:180] Creating CudaSolver handles for stream 0x55a186b682c0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "0.1\n",
      "[0.43905134078965097, 0.41487670125320036, 0.4335651142733937]\n",
      "0.42916438543874835\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "cca_train_met = MetricDict()\n",
    "for batch in dataprovider.training_data:\n",
    "    cca_train_met.update(batch)\n",
    "    \n",
    "cca_train = cca_train_met.output()\n",
    "    \n",
    "data_splits_for_acc = dataprovider.test_data\n",
    "\n",
    "results_dict = dict()\n",
    "\n",
    "for cca_dim in tqdm([120, 110, 100, 90, 80, 70, 60,]):\n",
    "    results_dict[cca_dim] = dict()\n",
    "    for reg in tqdm([1e-1, 1e-2, 1e-3, 1e-4, 1e-5, ]):\n",
    "        try:\n",
    "            B1, B2, epsilon, omega, ccor, mean_v0, mean_v1 = CCA(\n",
    "                cca_train['nn_input_0'],\n",
    "                cca_train['nn_input_1'],\n",
    "                num_shared_dim=cca_dim,\n",
    "                    r1=reg,\n",
    "                    r2=reg\n",
    "                )\n",
    "\n",
    "            accs = []\n",
    "            for split in data_splits_for_acc:\n",
    "                outputs_met_train, labels_met_train = MetricDict(), MetricDict()\n",
    "                for data in split['train']:\n",
    "\n",
    "                    m = tf.cast(tf.shape(data['nn_input_0'])[:1], tf.float32)\n",
    "                    v0_bar = tf.subtract(data['nn_input_0'], mean_v0) \n",
    "                    v1_bar = tf.subtract(data['nn_input_1'], mean_v1)\n",
    "                    epsilon = B1@tf.transpose(v0_bar)\n",
    "                    omega = B2@tf.transpose(v1_bar)\n",
    "\n",
    "                    cca_transformed_0 = epsilon.numpy().T\n",
    "                    cca_transformed_1 = omega.numpy().T\n",
    "\n",
    "                    outputs_met_train.update(dict(latent_view_0=cca_transformed_0, latent_view_1=cca_transformed_1))\n",
    "                    labels_met_train.update(dict(labels=data['labels'].numpy()))\n",
    "\n",
    "                netw_output_train = outputs_met_train.output()\n",
    "                labels_train = labels_met_train.output()['labels']\n",
    "                X_train = netw_output_train['latent_view_0']\n",
    "\n",
    "                scaler = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "                X_train = scaler.transform(X_train)    \n",
    "\n",
    "                svm_model = SVM(random_state=333)\n",
    "                svm_model.fit(X_train, labels_train)\n",
    "\n",
    "                outputs_met_val, labels_met_val = MetricDict(), MetricDict()\n",
    "                for data in split['val']:\n",
    "\n",
    "                    m = tf.cast(tf.shape(data['nn_input_0'])[:1], tf.float32)\n",
    "                    v0_bar = tf.subtract(data['nn_input_0'], mean_v0) \n",
    "                    v1_bar = tf.subtract(data['nn_input_1'], mean_v1)\n",
    "                    epsilon = B1@tf.transpose(v0_bar)\n",
    "                    omega = B2@tf.transpose(v1_bar)\n",
    "\n",
    "                    cca_transformed_0 = epsilon.numpy().T\n",
    "                    cca_transformed_1 = omega.numpy().T\n",
    "\n",
    "                    outputs_met_val.update(dict(latent_view_0=cca_transformed_0, latent_view_1=cca_transformed_1))\n",
    "                    labels_met_val.update(dict(labels=data['labels'].numpy()))\n",
    "\n",
    "                netw_output_val = outputs_met_val.output()\n",
    "                labels_val = labels_met_val.output()['labels']\n",
    "\n",
    "                X_val = netw_output_val['latent_view_0']\n",
    "\n",
    "                X_val = scaler.transform(X_val)\n",
    "\n",
    "                predictions = svm_model.predict(X_val)\n",
    "                svm_acc = accuracy_score(labels_val, predictions)\n",
    "                accs.append(svm_acc)\n",
    "\n",
    "            results_dict[cca_dim][reg] = dict(accuracies=accs, mean=np.mean(accs))\n",
    "\n",
    "            print(cca_dim)\n",
    "            print(reg)\n",
    "            print(accs)\n",
    "            print(np.mean(accs))\n",
    "            print(\"---\")\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc129436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (system)",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
